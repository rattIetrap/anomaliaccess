{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113aac1d-1d95-49ae-a129-9d220f9aeab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Modul 'models.py' berhasil diimpor.\n",
      "==================================================\n",
      "       PELATIHAN MODEL DETEKSI ANOMALI (JUPYTER NOTEBOOK)       \n",
      "==================================================\n",
      "\n",
      "[INFO] Data training akan dibaca dari: C:\\Users\\RYNO-PC\\Skripsi\\data\\hasil_log_jan.txt\n",
      "[INFO] Model & Artefak akan disimpan di: C:\\Users\\RYNO-PC\\Skripsi\\trained_models_artifacts\n",
      "\n",
      "[INFO] File training 'data/hasil_log_jan.txt' ditemukan.\n"
     ]
    }
   ],
   "source": [
    "# Sel 1: Impor Pustaka dan Konfigurasi Awal\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd # Tambahkan ini jika Anda ingin melihat DataFrame secara langsung di notebook\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model # Meskipun train_autoencoder mengembalikan model, ini untuk konsistensi\n",
    "import time\n",
    "\n",
    "# Impor fungsi-fungsi yang diperlukan dari models.py\n",
    "# Pastikan models.py ada di direktori yang sama atau di PYTHONPATH\n",
    "try:\n",
    "    from models import (\n",
    "        parse_log_file, \n",
    "        preprocess_data, \n",
    "        train_autoencoder, \n",
    "        train_ocsvm\n",
    "    )\n",
    "    print(\"[INFO] Modul 'models.py' berhasil diimpor.\")\n",
    "except ImportError:\n",
    "    print(\"[ERROR] Gagal mengimpor 'models.py'. Pastikan file tersebut ada di direktori yang sama.\")\n",
    "    # Anda mungkin perlu menghentikan eksekusi di sini jika impor gagal\n",
    "    raise \n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"       PELATIHAN MODEL DETEKSI ANOMALI (JUPYTER NOTEBOOK)       \")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 1. Konfigurasi Path ---\n",
    "# !!! GANTI INI DENGAN PATH KE FILE LOG TRAINING NORMAL ANDA !!!\n",
    "TRAINING_LOG_FILE_PATH = 'data/hasil_log_jan.txt' # Contoh jika ada di folder 'data'\n",
    "\n",
    "# Direktori untuk menyimpan model dan artefak\n",
    "BASE_DIR = os.path.abspath('.') # Menggunakan direktori kerja notebook saat ini\n",
    "BASE_MODEL_DIR = os.path.join(BASE_DIR, \"trained_models_artifacts\")\n",
    "os.makedirs(BASE_MODEL_DIR, exist_ok=True) \n",
    "\n",
    "# Path output\n",
    "AUTOENCODER_MODEL_PATH = os.path.join(BASE_MODEL_DIR, \"trained_autoencoder_model.h5\")\n",
    "OCSVM_MODEL_PATH = os.path.join(BASE_MODEL_DIR, \"trained_ocsvm_model.joblib\")\n",
    "SCALER_PATH = os.path.join(BASE_MODEL_DIR, \"trained_scaler.joblib\")\n",
    "LABEL_ENCODERS_PATH = os.path.join(BASE_MODEL_DIR, \"trained_label_encoders.joblib\")\n",
    "TRAINING_MSE_AE_PATH = os.path.join(BASE_MODEL_DIR, \"training_mse_ae.npy\")\n",
    "\n",
    "print(f\"\\n[INFO] Data training akan dibaca dari: {os.path.abspath(TRAINING_LOG_FILE_PATH)}\")\n",
    "print(f\"[INFO] Model & Artefak akan disimpan di: {BASE_MODEL_DIR}\\n\")\n",
    "\n",
    "# --- 2. Cek File Training ---\n",
    "if not os.path.exists(TRAINING_LOG_FILE_PATH):\n",
    "    print(f\"[ERROR] File training log '{TRAINING_LOG_FILE_PATH}' tidak ditemukan!\")\n",
    "    print(\"[ERROR] Silakan perbarui variabel 'TRAINING_LOG_FILE_PATH' di sel ini dan coba lagi.\")\n",
    "else:\n",
    "    print(f\"[INFO] File training '{TRAINING_LOG_FILE_PATH}' ditemukan.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c914947-7d50-4ba9-8df4-4013ff2b9618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LANGKAH 1/5] Memulai parsing dan pra-pemrosesan data training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[LANGKAH 1/5] Memulai parsing dan pra-pemrosesan data training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_train_raw = \u001b[43mparse_log_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAINING_LOG_FILE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_train_raw.empty:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[ERROR] Parsing data gagal atau file log kosong.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Skripsi\\models.py:29\u001b[39m, in \u001b[36mparse_log_file\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m, errors=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Mencocokkan pasangan key=value, termasuk value yang mengandung spasi jika diapit tanda kutip\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mw+)=(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.*?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mS+)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\codecs.py:319\u001b[39m, in \u001b[36mBufferedIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[32m    315\u001b[39m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[32m    316\u001b[39m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[32m    321\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.buffer + \u001b[38;5;28minput\u001b[39m\n\u001b[32m    322\u001b[39m     (result, consumed) = \u001b[38;5;28mself\u001b[39m._buffer_decode(data, \u001b[38;5;28mself\u001b[39m.errors, final)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Sel 2: Parsing & Pra-pemrosesan Data\n",
    "\n",
    "if os.path.exists(TRAINING_LOG_FILE_PATH): # Lanjutkan hanya jika file ada\n",
    "    print(\"[LANGKAH 1/5] Memulai parsing dan pra-pemrosesan data training...\")\n",
    "    start_time = time.time()\n",
    "    df_train_raw = parse_log_file(TRAINING_LOG_FILE_PATH)\n",
    "\n",
    "    if df_train_raw.empty:\n",
    "        print(\"[ERROR] Parsing data gagal atau file log kosong.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Parsing selesai. Jumlah record mentah: {len(df_train_raw)}\")\n",
    "        print(\"[INFO] Menampilkan beberapa baris data mentah (head):\")\n",
    "        display(df_train_raw.head()) # Gunakan display() di Jupyter untuk output yang lebih baik\n",
    "\n",
    "        print(\"\\n[INFO] Melakukan pra-pemrosesan (normalisasi, encoding, dll.)...\")\n",
    "        # Pastikan fungsi preprocess_data dari models.py dipanggil dengan benar\n",
    "        df_train_scaled, scaler, label_encoders, feature_cols, df_original_for_output_train = preprocess_data(\n",
    "            df_train_raw.copy(), \n",
    "            is_training=True\n",
    "        )\n",
    "\n",
    "        if df_train_scaled is None or df_train_scaled.empty:\n",
    "            print(\"[ERROR] Pra-pemrosesan data gagal.\")\n",
    "        else:\n",
    "            end_time = time.time()\n",
    "            print(f\"[SUKSES] Pra-pemrosesan data selesai. Shape data ter-scaled: {df_train_scaled.shape}. Waktu: {end_time - start_time:.2f} detik.\")\n",
    "            print(\"[INFO] Menampilkan beberapa baris data yang sudah diproses dan di-scaled (head):\")\n",
    "            display(df_train_scaled.head())\n",
    "            print(f\"[INFO] Kolom fitur yang digunakan: {feature_cols}\")\n",
    "else:\n",
    "    print(\"[SKIP] Langkah parsing dan pra-pemrosesan dilewati karena file training tidak ditemukan.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5abe73-51ba-4340-aed9-fcad9728c4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LANGKAH 2/5] Menyimpan Scaler dan Label Encoders...\n",
      "[SUKSES] Scaler disimpan di: C:\\Users\\RYNO-PC\\Skripsi\\trained_models_artifacts\\trained_scaler.joblib\n",
      "[SUKSES] Label Encoders disimpan di: C:\\Users\\RYNO-PC\\Skripsi\\trained_models_artifacts\\trained_label_encoders.joblib\n"
     ]
    }
   ],
   "source": [
    "# Sel 3: Simpan Scaler & Label Encoders\n",
    "\n",
    "if 'scaler' in locals() and 'label_encoders' in locals() and scaler and label_encoders: # Cek apakah variabel ada\n",
    "    print(\"\\n[LANGKAH 2/5] Menyimpan Scaler dan Label Encoders...\")\n",
    "    try:\n",
    "        joblib.dump(scaler, SCALER_PATH)\n",
    "        joblib.dump(label_encoders, LABEL_ENCODERS_PATH)\n",
    "        print(f\"[SUKSES] Scaler disimpan di: {SCALER_PATH}\")\n",
    "        print(f\"[SUKSES] Label Encoders disimpan di: {LABEL_ENCODERS_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Gagal menyimpan scaler/encoders: {e}\")\n",
    "else:\n",
    "    print(\"[SKIP] Langkah penyimpanan scaler/encoders dilewati karena variabel tidak ditemukan (mungkin error di pra-pemrosesan).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc1e7e29-e934-4b3f-940b-4ff41275267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LANGKAH 3/5] Melatih model Autoencoder...\n",
      "Melatih Autoencoder dengan 50 epochs...\n",
      "Epoch 1/50\n",
      "\u001b[1m43/62\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1430 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1246 - val_loss: 0.0340\n",
      "Epoch 2/50\n",
      "\u001b[1m44/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0331 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0316 - val_loss: 0.0121\n",
      "Epoch 3/50\n",
      "\u001b[1m46/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0168 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0163 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      "\u001b[1m45/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "\u001b[1m43/62\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0067 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "\u001b[1m38/62\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 9.7460e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m48/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038 - val_loss: 8.5895e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m47/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 7.9938e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m49/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 6.9295e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m48/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0025 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 6.7866e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m49/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 6.3864e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 6.6382e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m47/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 5.4582e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 5.7457e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m48/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 4.4493e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m48/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 4.1159e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m48/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 3.9948e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m46/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - val_loss: 3.7482e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m48/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 3.4300e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m47/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - val_loss: 3.0314e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 3.1274e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m44/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 2.9126e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m50/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 2.8567e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m42/62\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0011     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - val_loss: 2.6027e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 2.8603e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 3.0245e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 2.9394e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4133e-04 - val_loss: 2.7445e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1995e-04 - val_loss: 2.9128e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7506e-04 - val_loss: 2.6228e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4138e-04 - val_loss: 2.8485e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m41/62\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.6999e-04 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6319e-04 - val_loss: 2.5786e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9132e-04 - val_loss: 2.9029e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8518e-04 - val_loss: 3.8229e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m40/62\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.1010e-04 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1328e-04 - val_loss: 2.3995e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1290e-04 - val_loss: 2.8031e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8924e-04 - val_loss: 2.6349e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7692e-04 - val_loss: 2.8359e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m42/62\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4292e-04 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4363e-04 - val_loss: 2.2125e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0917e-04 - val_loss: 3.3065e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2102e-04 - val_loss: 2.3180e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5232e-04 - val_loss: 2.3642e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7539e-04 - val_loss: 2.3939e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1835e-04 - val_loss: 2.3452e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9188e-04 - val_loss: 2.6941e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1266e-04 - val_loss: 2.7061e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6638e-04 - val_loss: 2.4267e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2621e-04 - val_loss: 2.5460e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1723e-04 - val_loss: 2.8323e-04\n",
      "Autoencoder dilatih dan model terbaik disimpan di C:\\Users\\RYNO-PC\\Skripsi\\trained_models_artifacts\\trained_autoencoder_model.h5\n",
      "Gagal memuat model terbaik dari C:\\Users\\RYNO-PC\\Skripsi\\trained_models_artifacts\\trained_autoencoder_model.h5: Could not locate function 'mse'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'keras.metrics', 'class_name': 'function', 'config': 'mse', 'registered_name': 'mse'}. Mengembalikan model terakhir.\n",
      "[SUKSES] Model Autoencoder dilatih dan disimpan. Waktu: 10.44 detik.\n",
      "\n",
      "[LANGKAH 4/5] Menghitung & Menyimpan MSE Training Autoencoder...\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "[SUKSES] Training MSE untuk Autoencoder disimpan di: C:\\Users\\RYNO-PC\\Skripsi\\trained_models_artifacts\\training_mse_ae.npy\n",
      "[INFO] Statistik MSE Training: Min=0.000014, Max=0.011153, Mean=0.000232, Median=0.000150\n"
     ]
    }
   ],
   "source": [
    "# Sel 4: Latih & Simpan Autoencoder, Hitung & Simpan MSE Training\n",
    "\n",
    "if 'df_train_scaled' in locals() and not df_train_scaled.empty: # Cek apakah data training ada\n",
    "    print(\"\\n[LANGKAH 3/5] Melatih model Autoencoder...\")\n",
    "    start_time_ae = time.time()\n",
    "    input_dim = df_train_scaled.shape[1]\n",
    "    \n",
    "    # Anda bisa menyesuaikan epochs di sini\n",
    "    autoencoder_model, history_ae = train_autoencoder(\n",
    "        df_train_scaled, \n",
    "        input_dim=input_dim, \n",
    "        model_save_path=AUTOENCODER_MODEL_PATH, \n",
    "        epochs=50 # Contoh epochs, bisa disesuaikan\n",
    "    )\n",
    "\n",
    "    if autoencoder_model:\n",
    "        end_time_ae = time.time()\n",
    "        print(f\"[SUKSES] Model Autoencoder dilatih dan disimpan. Waktu: {end_time_ae - start_time_ae:.2f} detik.\")\n",
    "        \n",
    "        # Plot history jika mau (membutuhkan matplotlib)\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # plt.plot(history_ae.history['loss'], label='Training Loss')\n",
    "        # plt.plot(history_ae.history['val_loss'], label='Validation Loss')\n",
    "        # plt.title('Autoencoder Model Loss')\n",
    "        # plt.ylabel('Loss (MSE)')\n",
    "        # plt.xlabel('Epoch')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "\n",
    "        print(\"\\n[LANGKAH 4/5] Menghitung & Menyimpan MSE Training Autoencoder...\")\n",
    "        try:\n",
    "            train_predictions_ae = autoencoder_model.predict(df_train_scaled)\n",
    "            # Pastikan df_train_scaled adalah numpy array untuk operasi pengurangan jika perlu\n",
    "            df_train_scaled_np = df_train_scaled.to_numpy() if isinstance(df_train_scaled, pd.DataFrame) else df_train_scaled\n",
    "            training_mse_ae = np.mean(np.power(df_train_scaled_np - train_predictions_ae, 2), axis=1)\n",
    "            \n",
    "            np.save(TRAINING_MSE_AE_PATH, training_mse_ae)\n",
    "            print(f\"[SUKSES] Training MSE untuk Autoencoder disimpan di: {TRAINING_MSE_AE_PATH}\")\n",
    "            print(f\"[INFO] Statistik MSE Training: Min={training_mse_ae.min():.6f}, Max={training_mse_ae.max():.6f}, Mean={training_mse_ae.mean():.6f}, Median={np.median(training_mse_ae):.6f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Gagal menghitung atau menyimpan MSE training: {e}\")\n",
    "    else:\n",
    "        print(\"[ERROR] Pelatihan Autoencoder gagal.\")\n",
    "else:\n",
    "    print(\"[SKIP] Langkah pelatihan Autoencoder dilewati karena data training (df_train_scaled) tidak tersedia.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769bc67c-6c3d-4ac5-ac75-6ec4c8aaa67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LANGKAH 5/5] Melatih model One-Class SVM...\n",
      "Melatih OC-SVM...\n",
      "OC-SVM dilatih dan disimpan di C:\\Users\\RYNO-PC\\Skripsi\\trained_models_artifacts\\trained_ocsvm_model.joblib\n",
      "[SUKSES] Model One-Class SVM dilatih dan disimpan. Waktu: 0.02 detik.\n",
      "\n",
      "==================================================\n",
      "     PELATIHAN MODEL SELESAI!     \n",
      "==================================================\n",
      "Periksa folder 'trained_models_artifacts' untuk file-file yang dihasilkan.\n"
     ]
    }
   ],
   "source": [
    "# Sel 5: Latih & Simpan One-Class SVM\n",
    "\n",
    "if 'df_train_scaled' in locals() and not df_train_scaled.empty: # Cek apakah data training ada\n",
    "    print(\"\\n[LANGKAH 5/5] Melatih model One-Class SVM...\")\n",
    "    start_time_ocsvm = time.time()\n",
    "    \n",
    "    ocsvm_model = train_ocsvm(\n",
    "        df_train_scaled, \n",
    "        model_save_path=OCSVM_MODEL_PATH\n",
    "    )\n",
    "\n",
    "    if ocsvm_model:\n",
    "        end_time_ocsvm = time.time()\n",
    "        print(f\"[SUKSES] Model One-Class SVM dilatih dan disimpan. Waktu: {end_time_ocsvm - start_time_ocsvm:.2f} detik.\")\n",
    "        \n",
    "        # Anda bisa mencoba memprediksi beberapa sampel dari data training untuk melihat hasilnya\n",
    "        # if len(df_train_scaled) > 0:\n",
    "        #     predictions_ocsvm_sample = ocsvm_model.predict(df_train_scaled.head())\n",
    "        #     decision_scores_sample = ocsvm_model.decision_function(df_train_scaled.head())\n",
    "        #     print(\"\\n[INFO] Contoh prediksi OC-SVM pada data training (head):\")\n",
    "        #     print(f\"Label (-1 anomali, 1 normal): {predictions_ocsvm_sample}\")\n",
    "        #     print(f\"Skor Keputusan: {decision_scores_sample}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"[ERROR] Pelatihan One-Class SVM gagal.\")\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"     PELATIHAN MODEL SELESAI!     \")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Periksa folder 'trained_models_artifacts' untuk file-file yang dihasilkan.\")\n",
    "\n",
    "else:\n",
    "    print(\"[SKIP] Langkah pelatihan One-Class SVM dilewati karena data training (df_train_scaled) tidak tersedia.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b1e90-4974-49c1-bc37-f6abd4155b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsivenv",
   "language": "python",
   "name": "skripsivenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
